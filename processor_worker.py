import os
import json
import time
import redis
import ffmpeg
import cv2
from pathlib import Path

redis_client = redis.from_url(
    os.environ["REDIS_URL"],
    decode_responses=True
)

print("ğŸ”Œ Redis connected in Worker")

def process_video_task(task_data):
    print(f"æ­£åœ¨å¤„ç†ä»»åŠ¡: {task_data}")

    task_type = task_data.get('type')
    task_id = task_data.get('task_id')

    try:
        if task_type == 'video_generation':
            result = generate_video_with_sora(task_data)
        elif task_type == 'video_analysis':
            result = analyze_video_style(task_data)
        elif task_type == 'digital_human':
            result = generate_digital_human_video(task_data)
        elif task_type == 'video_processing':
            result = process_video_file(task_data)
        else:
            raise ValueError(f"æœªçŸ¥ä»»åŠ¡ç±»å‹: {task_type}")

        update_task_status(task_id, "completed", 100, result)
        print(f"âœ… ä»»åŠ¡å®Œæˆ: {task_id}")

    except Exception as e:
        print(f"âŒ ä»»åŠ¡å¤±è´¥: {task_id}, é”™è¯¯: {str(e)}")
        update_task_status(task_id, 'failed', 0, None, str(e))


def generate_video_with_sora(task_data):
    prompt = task_data.get('prompt', '')
    style = task_data.get('style', 'cinematic')
    duration = task_data.get('duration', 5)

    print(f"ç”Ÿæˆè§†é¢‘ - æç¤ºè¯: {prompt}, é£æ ¼: {style}, æ—¶é•¿: {duration}s")

    time.sleep(5)

    return {
        'video_url': f'/generated/{task_data.get("task_id")}.mp4',
        'thumbnail_url': f'/thumbnails/{task_data.get("task_id")}.jpg',
        'duration': duration,
        'resolution': '1920x1080',
        'format': 'mp4'
    }


def analyze_video_style(task_data):
    video_path = task_data.get('video_path')

    if not video_path or not os.path.exists(video_path):
        raise FileNotFoundError(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")

    print(f"åˆ†æè§†é¢‘é£æ ¼: {video_path}")

    cap = cv2.VideoCapture(video_path)
    frames = []

    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    fps = cap.get(cv2.CAP_PROP_FPS)

    for i in range(0, frame_count, int(fps)):
        cap.set(cv2.CAP_PROP_POS_FRAMES, i)
        ret, frame = cap.read()
        if ret:
            frames.append(frame)

    cap.release()

    style_tags = []
    if len(frames) > 0:
        avg_brightness = sum(cv2.mean(frame)[0] for frame in frames) / len(frames)
        if avg_brightness > 150:
            style_tags.append('æ˜äº®')
        elif avg_brightness < 100:
            style_tags.append('æš—è‰²è°ƒ')

        motion_score = 0
        for i in range(1, len(frames)):
            diff = cv2.absdiff(frames[i-1], frames[i])
            motion_score += cv2.mean(diff)[0]

        if motion_score / len(frames) > 50:
            style_tags.append('åŠ¨æ€')
        else:
            style_tags.append('é™æ€')

    return {
        'style_tags': style_tags,
        'frame_count': len(frames),
        'fps': fps,
        'duration': frame_count / fps if fps > 0 else 0,
        'resolution': f"{int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))}x{int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))}"
    }


def generate_digital_human_video(task_data):
    script = task_data.get('script', '')
    print(f"ç”Ÿæˆæ•°å­—äººè§†é¢‘ - è„šæœ¬: {script[:50]}...")

    time.sleep(10)

    return {
        'video_url': f'/digital_human/{task_data.get("task_id")}.mp4',
        'audio_url': f'/audio/{task_data.get("task_id")}.wav',
        'lip_sync_score': 0.95,
        'processing_time': 10
    }


def process_video_file(task_data):
    operation = task_data.get('operation', 'slice')
    input_path = task_data.get('input_path')
    output_path = task_data.get('output_path')

    if not input_path or not os.path.exists(input_path):
        raise FileNotFoundError(f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_path}")

    print(f"å¤„ç†è§†é¢‘æ–‡ä»¶ - æ“ä½œ: {operation}, è¾“å…¥: {input_path}")

    if operation == 'slice':
        start_time = task_data.get('start_time', 0)
        duration = task_data.get('duration', 10)
        stream = ffmpeg.input(input_path, ss=start_time, t=duration)
        stream = ffmpeg.output(stream, output_path, vcodec='libx264', acodec='aac')
        ffmpeg.run(stream, overwrite_output=True)

    return {
        'output_path': output_path,
        'operation': operation,
        'processed_at': time.time()
    }


def update_task_status(task_id, status, progress, result=None, error=None):
    status_data = {
        "task_id": task_id,
        "status": status,
        "progress": progress,
        "timestamp": time.time(),
    }

    if result is not None:
        status_data["result"] = result
    if error is not None:
        status_data["error"] = error

    redis_client.setex(f"task:{task_id}", 3600, json.dumps(status_data))


def run_worker():
    print("ğŸš€ AI Worker å·²å¯åŠ¨ï¼Œç›‘å¬ä»»åŠ¡é˜Ÿåˆ— pending_task:* ...")

    while True:
        try:
            task_keys = redis_client.keys("pending_task:*")
            for key in task_keys:
                raw = redis_client.get(key)
                if not raw:
                    redis_client.delete(key)
                    continue

                task_data = json.loads(raw)
                redis_client.delete(key)

                process_video_task(task_data)

        except Exception as e:
            print(f"âš ï¸ Worker é”™è¯¯: {str(e)}")

        time.sleep(1)
